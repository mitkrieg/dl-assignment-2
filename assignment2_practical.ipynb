{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitkrieg/dl-assignment-2/blob/main/assignment2_practical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijX0qBNZlwRY",
        "outputId": "3efa0f36-1d75-4cbe-b149-749704f02feb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.14.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmitkrieger\u001b[0m (\u001b[33mmitkrieger-cornell-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXlIsAxnaoz5",
        "outputId": "c86e1a17-7931-46ef-8a2a-10a7477d06f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ ACCELERATION INFO -----\n",
            "CUDA GPU Available: True\n",
            "MPS GPU Available: False\n",
            "GPU Name: Tesla T4\n",
            "GPU Count: 1\n",
            "GPU Memory Allocated: 247080448\n",
            "GPU Memory Cached: 339738624\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import wandb\n",
        "\n",
        "print(\"------ ACCELERATION INFO -----\")\n",
        "print('CUDA GPU Available:',torch.cuda.is_available())\n",
        "print('MPS GPU Available:', torch.backends.mps.is_available())\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print('GPU Name:',torch.cuda.get_device_name(0))\n",
        "  print('GPU Count:',torch.cuda.device_count())\n",
        "  print('GPU Memory Allocated:',torch.cuda.memory_allocated(0))\n",
        "  print('GPU Memory Cached:',torch.cuda.memory_reserved(0))\n",
        "# elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "#   device = torch.device('mps')\n",
        "#   print('Pytorch GPU Build:',torch.backends.mps.is_built())\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('Using CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9d895XBaoz6"
      },
      "source": [
        "## Define PTBText Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TmKDKXflaoz7"
      },
      "outputs": [],
      "source": [
        "class PTBText(Dataset):\n",
        "    def __init__(self, filename, sequence_len, prior_vocab=None,device=torch.device('cpu')) -> None:\n",
        "        super().__init__()\n",
        "        self.tokenized_text = []\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.device = device\n",
        "        self.tokenizer = RegexpTokenizer(r'<unk>|<pad>|<oov>|<sos>|<eos>|\\w+').tokenize\n",
        "        self.seq_len = sequence_len\n",
        "        self.max_len = 0\n",
        "        if prior_vocab:\n",
        "            self.vocab = prior_vocab\n",
        "        else:\n",
        "            self.vocab = {'<pad>':0,'<oov>':1,'<sos>':2,'<eos>':3,'<unk>':4}\n",
        "\n",
        "        with open(filename, 'r') as f:\n",
        "            for line in f:\n",
        "                tokens = self.tokenizer(line)\n",
        "\n",
        "                #only build new vocab if prior vocab is not given\n",
        "                if prior_vocab is None:\n",
        "                    idx = len(self.vocab)\n",
        "                    for word in tokens:\n",
        "                        if word not in self.vocab:\n",
        "                            self.vocab[word] = idx\n",
        "                            idx += 1\n",
        "\n",
        "                self.tokenized_text.append(tokens + ['<eos>'])\n",
        "                self.max_len = max(self.max_len, len(tokens) + 2)\n",
        "\n",
        "\n",
        "        self.encoded_text = [self.encode_text(x, pad=True) for x in self.tokenized_text]\n",
        "\n",
        "        #build sequences\n",
        "        for tokens in self.tokenized_text:\n",
        "            for i in range(len(tokens) - self.seq_len):\n",
        "                self.data.append(tokens[i:i+self.seq_len])\n",
        "                self.labels.append(tokens[i+1:i+self.seq_len+1])\n",
        "        self.encoded_labels = [self.encode_text(x) for x in self.labels]\n",
        "        self.encoded_data = [self.encode_text(x) for x in self.data]\n",
        "\n",
        "    def encode_text(self, tokens: list[str], pad=False):\n",
        "        encoded = []\n",
        "        for word in tokens:\n",
        "            encoded.append(self.vocab.get(word,1))\n",
        "\n",
        "        if pad and len(encoded) < self.max_len:\n",
        "            encoded.extend([0]* (self.max_len - len(encoded)))\n",
        "        elif len(encoded) < self.seq_len:\n",
        "            encoded.extend([0]*(self.seq_len - len(encoded)))\n",
        "\n",
        "        return encoded\n",
        "\n",
        "    def resequence_data(self, seqence_len):\n",
        "        self.seq_len = seqence_len\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        for tokens in self.tokenized_text:\n",
        "            for i in range(len(tokens) - self.seq_len):\n",
        "                self.data.append(tokens[i:i+self.seq_len])\n",
        "                self.labels.append(tokens[i+self.seq_len])\n",
        "\n",
        "        self.encoded_labels = [self.vocab.get(x,1) for x in self.labels]\n",
        "        self.encoded_data = [self.encode_text(x) for x in self.data]\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.tensor(self.encoded_data[index]).to(self.device), torch.tensor(self.encoded_labels[index]).to(self.device)\n",
        "\n",
        "    def get_tokens(self, index):\n",
        "        return self.tokenized_text[index]\n",
        "\n",
        "    def get_encoded_tokens(self, index):\n",
        "        return self.encoded_text[index]\n",
        "\n",
        "    def get_sequence(self, index):\n",
        "        return self.data[index], self.labels[index]\n",
        "\n",
        "    def get_encoded_sequence(self, index):\n",
        "        return self.__getitem__(index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZubswHHaoz7"
      },
      "source": [
        "### Load Data & Create Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhw_Ric-aoz7",
        "outputId": "5d2d71e7-576f-4b00-ebe7-be75b4e642a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training vocab size: 9648\n",
            "Training sample raw:  (['of', 'asbestos', 'including', '<unk>', 'more', '<unk>', 'than', 'the', 'common', 'kind', 'of', 'asbestos', '<unk>', 'found', 'in', 'most', 'schools', 'and', 'other', 'buildings'], ['asbestos', 'including', '<unk>', 'more', '<unk>', 'than', 'the', 'common', 'kind', 'of', 'asbestos', '<unk>', 'found', 'in', 'most', 'schools', 'and', 'other', 'buildings', 'dr'])\n",
            "Training sample encoded: (tensor([ 47,  67, 209,   4,  85,   4,  86,  37, 246, 247,  47,  67,   4, 248,\n",
            "        115, 249, 178,  54, 250, 251]), tensor([ 67, 209,   4,  85,   4,  86,  37, 246, 247,  47,  67,   4, 248, 115,\n",
            "        249, 178,  54, 250, 251, 172]))\n"
          ]
        }
      ],
      "source": [
        "seq_len = 20\n",
        "train = PTBText('/content/ptb.train.txt', seq_len)\n",
        "val = PTBText('/content/ptb.valid.txt', seq_len, prior_vocab=train.vocab)\n",
        "test = PTBText('/content/ptb.test.txt', seq_len, prior_vocab=train.vocab)\n",
        "\n",
        "gen = torch.Generator().manual_seed(123)\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, generator=gen)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=True, generator=gen)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, generator=gen)\n",
        "\n",
        "dataloaders = {\n",
        "    'train':train_loader,\n",
        "    'val':val_loader,\n",
        "    'test':test_loader\n",
        "}\n",
        "\n",
        "print('Training vocab size:', len(train.vocab))\n",
        "print('Training sample raw: ', train.get_sequence(100))\n",
        "print('Training sample encoded:',train[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBtifwp8aoz8"
      },
      "source": [
        "## Define LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "z9KNjkJ0aoz8"
      },
      "outputs": [],
      "source": [
        "class ZarembaRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_units=200, num_lstm_layers=2, dropout_rate= 0) -> None:\n",
        "        super().__init__()\n",
        "        self.hidden_units = hidden_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_size = embedding_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        nn.init.xavier_uniform_(self.embedding.weight, generator=torch.Generator().manual_seed(1))\n",
        "        self.lstm = nn.LSTM(embedding_size,hidden_units, num_lstm_layers, batch_first=True)\n",
        "        nn.init.xavier_uniform_(self.lstm.weight_ih_l0, generator=torch.Generator().manual_seed(2))\n",
        "        nn.init.xavier_uniform_(self.lstm.weight_hh_l0, generator=torch.Generator().manual_seed(3))\n",
        "        self.fc = nn.Linear(hidden_units, vocab_size)\n",
        "        nn.init.xavier_uniform_(self.fc.weight, generator=torch.Generator().manual_seed(4))\n",
        "        self.dropout_rate = dropout_rate\n",
        "        if self.dropout_rate > 0:\n",
        "            self.dropout = nn.Dropout(self.dropout_rate)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "\n",
        "        hidden = (hidden[0].contiguous(), hidden[1].contiguous())\n",
        "        x = self.embedding(x)\n",
        "        x, hidden = self.lstm(x, hidden)\n",
        "        if self.dropout_rate > 0:\n",
        "            x = self.dropout(x)\n",
        "            x = self.fc(x)\n",
        "        else:\n",
        "            x = self.fc(x)\n",
        "\n",
        "\n",
        "        return x, hidden\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "ylH6Tu6yaoz8"
      },
      "outputs": [],
      "source": [
        "def train_epoch(network, dataloader, loss_fn, optimizer, device, epoch, verbosity: int):\n",
        "    \"\"\"Train one epoch of a network\"\"\"\n",
        "\n",
        "    network.train()\n",
        "    batch_loss = 0\n",
        "\n",
        "    # iterate over all batches\n",
        "    for i, data in enumerate(dataloader):\n",
        "        #reset hidden state for batch\n",
        "        hidden= (torch.zeros(2, batch_size, 200).to(device), torch.zeros(2, batch_size, 200).to(device))\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        if inputs.size(0) != batch_size:\n",
        "            hidden = (hidden[0][:, :inputs.size(0), :], hidden[1][:, :inputs.size(0), :])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, hidden = network(inputs, hidden)\n",
        "\n",
        "        hidden = (hidden[0].detach(), hidden[1].detach())\n",
        "\n",
        "\n",
        "\n",
        "        output_reshaped = outputs.view(-1, outputs.size(-1))\n",
        "        labels_reshaped = labels.view(-1)\n",
        "\n",
        "        loss = loss_fn(output_reshaped, labels_reshaped)\n",
        "        loss.backward()\n",
        "\n",
        "        #gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(network.parameters(), max_norm=2)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_loss += loss.item()\n",
        "        if i % verbosity == verbosity - 1:\n",
        "            print(f'Batch #{i + 1} Loss: {batch_loss / verbosity}')\n",
        "            batch_loss = 0\n",
        "\n",
        "def perplexity(loss, batches):\n",
        "    return math.exp(loss / batches)\n",
        "\n",
        "def eval_network(title, network, dataloader, loss_fn, epoch):\n",
        "    \"\"\"Evaluate model and log metrics to wandb\"\"\"\n",
        "\n",
        "    network.eval()\n",
        "    total = 0\n",
        "    loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            data, labels = data\n",
        "            data = data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            hidden= (torch.zeros(2, batch_size, 200).to(device), torch.zeros(2, batch_size, 200).to(device))\n",
        "            if data.size(0) != batch_size:\n",
        "              hidden = (hidden[0][:, :data.size(0), :], hidden[1][:, :data.size(0), :])\n",
        "\n",
        "            outputs, hidden = network(data, hidden)\n",
        "\n",
        "            output_reshaped = outputs.view(-1, outputs.size(-1))\n",
        "            labels_reshaped = labels.view(-1)\n",
        "\n",
        "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
        "\n",
        "            loss += loss_fn(output_reshaped, labels_reshaped)\n",
        "            total += labels.size(0)\n",
        "\n",
        "        perp = perplexity(loss, len(dataloader))\n",
        "\n",
        "        wandb.log({\n",
        "            f'{title}-loss': loss / len(dataloader),\n",
        "            f'{title}-perplexity': perp\n",
        "        }, step=epoch)\n",
        "\n",
        "    print(f'\\033[92m{title} perplexity: {perp:.6f} ||| loss {loss / len(dataloader):.6f}\\033[0m')\n",
        "\n",
        "    return perp\n",
        "\n",
        "def train_network(network, dataloaders, loss_fn, optimizer, schedule, device, epochs: int, verbosity: int):\n",
        "    for epoch in range(epochs):\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        print(f'----------- Epoch #{epoch + 1}, LR: {lr} ------------')\n",
        "        train_epoch(network, dataloaders['train'], loss_fn, optimizer, device, epoch, verbosity)\n",
        "        train_perplexity = eval_network('Train', network, dataloaders['train'], loss_fn, epoch)\n",
        "        val_perplexity = eval_network('Validation', network, dataloaders['val'], loss_fn, epoch)\n",
        "        test_perplexity = eval_network('Test', network, dataloaders['test'], loss_fn, epoch)\n",
        "        print('------------------------------------\\n')\n",
        "\n",
        "        schedule.step()\n",
        "    print('----------- Train Complete! ------------')\n",
        "    return {\n",
        "        'train':train_perplexity,\n",
        "        'val':val_perplexity,\n",
        "        'test':test_perplexity\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "QxURR3Tlaoz8"
      },
      "outputs": [],
      "source": [
        "decay_start = 4\n",
        "learning_rate_decay = 0.5\n",
        "embedding_size = 200\n",
        "momentum=0.5\n",
        "lr_start=4\n",
        "dropout_rate = 0\n",
        "\n",
        "def lr_lambda(epoch):\n",
        "    if epoch < decay_start:\n",
        "        return 1\n",
        "    else:\n",
        "        return learning_rate_decay ** (epoch - (decay_start-1))\n",
        "\n",
        "model = ZarembaRNN(len(train.vocab), embedding_size)\n",
        "model = model.to(device)\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "sgd = optim.SGD(model.parameters(), lr=lr_start, momentum=momentum)\n",
        "schedule = optim.lr_scheduler.LambdaLR(sgd, lr_lambda)\n",
        "# device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d2bab034e253496caff156c8ba2046ce",
            "32a0681de34445b4bc5f35d21394d45b",
            "a176bef38c704a6aac8df29e80bb9f46",
            "1870aae9ad7c4afdae7a02e9baf97452",
            "82322c9868314e798f952ad8562ffff4",
            "4a9815d9e51e4b3d928652de24fdff97",
            "f3fbdddb225646b9b7cc1df65d3ab285",
            "9f306f3ad42b488880597be20744c774"
          ]
        },
        "id": "oZmvghb8aoz9",
        "outputId": "642aa318-fb34-49e6-cd29-c50cbf2507c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:7fy4697s) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2bab034e253496caff156c8ba2046ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test-loss</td><td>▁█</td></tr><tr><td>Test-perplexity</td><td>▁█</td></tr><tr><td>Train-loss</td><td>█▁</td></tr><tr><td>Train-perplexity</td><td>█▁</td></tr><tr><td>Validation-loss</td><td>▁█</td></tr><tr><td>Validation-perplexity</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test-loss</td><td>5.29157</td></tr><tr><td>Test-perplexity</td><td>198.65473</td></tr><tr><td>Train-loss</td><td>3.91129</td></tr><tr><td>Train-perplexity</td><td>49.96361</td></tr><tr><td>Validation-loss</td><td>5.34337</td></tr><tr><td>Validation-perplexity</td><td>209.21648</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dark-dew-54</strong> at: <a href='https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux/runs/7fy4697s' target=\"_blank\">https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux/runs/7fy4697s</a><br/> View project at: <a href='https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux' target=\"_blank\">https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240924_050108-7fy4697s/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:7fy4697s). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240924_050303-hvc2rhv0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux/runs/hvc2rhv0' target=\"_blank\">glorious-dragon-55</a></strong> to <a href='https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux' target=\"_blank\">https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux/runs/hvc2rhv0' target=\"_blank\">https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux/runs/hvc2rhv0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- Epoch #1, LR: 4 ------------\n",
            "Batch #500 Loss: 6.585322054862976\n",
            "Batch #1000 Loss: 5.951709095954895\n",
            "Batch #1500 Loss: 5.580817513465881\n",
            "\u001b[92mTrain perplexity: 214.617297 ||| loss 5.368856\u001b[0m\n",
            "\u001b[92mValidation perplexity: 254.992106 ||| loss 5.541233\u001b[0m\n",
            "\u001b[92mTest perplexity: 246.627186 ||| loss 5.507878\u001b[0m\n",
            "------------------------------------\n",
            "\n",
            "----------- Epoch #2, LR: 4 ------------\n",
            "Batch #500 Loss: 5.205941417694092\n",
            "Batch #1000 Loss: 5.029384421348571\n",
            "Batch #1500 Loss: 4.871192534446716\n",
            "\u001b[92mTrain perplexity: 112.797862 ||| loss 4.725597\u001b[0m\n",
            "\u001b[92mValidation perplexity: 191.102786 ||| loss 5.252811\u001b[0m\n",
            "\u001b[92mTest perplexity: 184.418023 ||| loss 5.217205\u001b[0m\n",
            "------------------------------------\n",
            "\n",
            "----------- Epoch #3, LR: 4 ------------\n",
            "Batch #500 Loss: 4.658250547409057\n",
            "Batch #1000 Loss: 4.544675675392151\n",
            "Batch #1500 Loss: 4.438771874427795\n",
            "\u001b[92mTrain perplexity: 75.808061 ||| loss 4.328205\u001b[0m\n",
            "\u001b[92mValidation perplexity: 192.898587 ||| loss 5.262165\u001b[0m\n",
            "\u001b[92mTest perplexity: 185.663446 ||| loss 5.223936\u001b[0m\n",
            "------------------------------------\n",
            "\n",
            "----------- Epoch #4, LR: 4 ------------\n",
            "Batch #500 Loss: 4.248585647583008\n",
            "Batch #1000 Loss: 4.182573686122894\n",
            "Batch #1500 Loss: 4.093178371429444\n",
            "\u001b[92mTrain perplexity: 52.436746 ||| loss 3.959608\u001b[0m\n",
            "\u001b[92mValidation perplexity: 206.509929 ||| loss 5.330348\u001b[0m\n",
            "\u001b[92mTest perplexity: 197.194991 ||| loss 5.284193\u001b[0m\n",
            "------------------------------------\n",
            "\n",
            "----------- Epoch #5, LR: 2.0 ------------\n",
            "Batch #500 Loss: 3.843076669216156\n",
            "Batch #1000 Loss: 3.783727822303772\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-c8237ea8ffa2>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m'seq_len'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m })\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-f09bea02f38f>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(network, dataloaders, loss_fn, optimizer, schedule, device, epochs, verbosity)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'----------- Epoch #{epoch + 1}, LR: {lr} ------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mtrain_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mval_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-f09bea02f38f>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(network, dataloader, loss_fn, optimizer, device, epoch, verbosity)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mverbosity\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mverbosity\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Batch #{i + 1} Loss: {batch_loss / verbosity}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "run = wandb.init(project=\"dl-assignment2-redux\", config={\n",
        "    'batch_size':batch_size,\n",
        "    'embedding_size':embedding_size,\n",
        "    'hidden_units':200,\n",
        "    'num_lstm_layers':2,\n",
        "    'dropout_rate':dropout_rate,\n",
        "    'epoch_decay_at':decay_start,\n",
        "    'learning_rate_decay':learning_rate_decay,\n",
        "    'learning_rate_start':lr_start,\n",
        "    'momentum':momentum,\n",
        "    'optimizer':'SGD',\n",
        "    'seq_len':seq_len\n",
        "})\n",
        "results = train_network(model, dataloaders, cross_entropy, sgd, schedule, device, 14, 500)\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "6dfefed33f754744b5f227d443e3c0a1",
            "eeb9b24c12c24bb2811849b2f45b6530",
            "d0839eb052484b8f8e8a63f1190ce2e7",
            "227abe00592c4ca89c1b39fd80ad4622",
            "3f066178dd1541a3a57c8e17cd792b5e",
            "3c65df30411a4520b2647687aacd0007",
            "2469c01d97004b37b7c130a0a369338e",
            "3870df2adba14c4d9d4e0fea39986507"
          ]
        },
        "id": "2PXc67pqnE05",
        "outputId": "bc4aed1a-bbfb-440a-bcb1-aba5475d10d2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.014 MB of 0.014 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dfefed33f754744b5f227d443e3c0a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test-loss</td><td>█▃▂▁▁▂▃</td></tr><tr><td>Test-perplexity</td><td>█▃▁▁▁▂▃</td></tr><tr><td>Train-loss</td><td>█▆▅▄▃▂▁</td></tr><tr><td>Train-perplexity</td><td>█▅▃▃▂▁▁</td></tr><tr><td>Validation-loss</td><td>█▃▂▁▁▃▄</td></tr><tr><td>Validation-perplexity</td><td>█▃▁▁▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test-loss</td><td>5.31243</td></tr><tr><td>Test-perplexity</td><td>202.84242</td></tr><tr><td>Train-loss</td><td>3.79466</td></tr><tr><td>Train-perplexity</td><td>44.46323</td></tr><tr><td>Validation-loss</td><td>5.35984</td></tr><tr><td>Validation-perplexity</td><td>212.69039</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dazzling-cosmos-48</strong> at: <a href='https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux/runs/dlit53i2' target=\"_blank\">https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux/runs/dlit53i2</a><br/> View project at: <a href='https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux' target=\"_blank\">https://wandb.ai/mitkrieger-cornell-university/dl-assignment2-redux</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240924_040929-dlit53i2/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_loader:\n",
        "    inputs, labels = data\n",
        "    print(inputs.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuDGSOwgvZm9",
        "outputId": "faa0fa03-0369-496b-87a7-524ac5a94109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_lambda(epoch):\n",
        "    if epoch < 7:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0.5 ** (epoch - 6)\n",
        "\n",
        "model = ZarembaRNN(len(train.vocab), 10)\n",
        "model = model.to(device)\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "adam = optim.Adam(model.parameters(), lr=1e-2)\n",
        "schedule = optim.lr_scheduler.LambdaLR(adam, lr_lambda)\n",
        "# device = torch.device('cpu')\n"
      ],
      "metadata": {
        "id": "lvN_lQb-dGa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kDZNx82PIVEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs, hidden = model(inputs.to(device), (torch.zeros(2, batch_size, 200).to(device), torch.zeros(2, batch_size, 200).to(device)))\n",
        "    # outputs, hidden = network(inputs, hidden)\n",
        "\n",
        "    hidden = (hidden[0].detach(), hidden[1].detach())\n",
        "\n",
        "\n",
        "\n",
        "    output_reshaped = outputs.view(-1, outputs.size(-1))\n",
        "    labels_reshaped = labels.view(-1)\n",
        "    # print(output_reshaped.device)\n",
        "    # print(labels_reshaped.device)\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()(output_reshaped, labels_reshaped)\n",
        "    print(loss)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKf_vC3gcZcT",
        "outputId": "ec39c237-1b9c-49d6-c64c-3e2917f887ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9.1814, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2bab034e253496caff156c8ba2046ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32a0681de34445b4bc5f35d21394d45b",
              "IPY_MODEL_a176bef38c704a6aac8df29e80bb9f46"
            ],
            "layout": "IPY_MODEL_1870aae9ad7c4afdae7a02e9baf97452"
          }
        },
        "32a0681de34445b4bc5f35d21394d45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82322c9868314e798f952ad8562ffff4",
            "placeholder": "​",
            "style": "IPY_MODEL_4a9815d9e51e4b3d928652de24fdff97",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "a176bef38c704a6aac8df29e80bb9f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3fbdddb225646b9b7cc1df65d3ab285",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f306f3ad42b488880597be20744c774",
            "value": 1
          }
        },
        "1870aae9ad7c4afdae7a02e9baf97452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82322c9868314e798f952ad8562ffff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a9815d9e51e4b3d928652de24fdff97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3fbdddb225646b9b7cc1df65d3ab285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f306f3ad42b488880597be20744c774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dfefed33f754744b5f227d443e3c0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeb9b24c12c24bb2811849b2f45b6530",
              "IPY_MODEL_d0839eb052484b8f8e8a63f1190ce2e7"
            ],
            "layout": "IPY_MODEL_227abe00592c4ca89c1b39fd80ad4622"
          }
        },
        "eeb9b24c12c24bb2811849b2f45b6530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f066178dd1541a3a57c8e17cd792b5e",
            "placeholder": "​",
            "style": "IPY_MODEL_3c65df30411a4520b2647687aacd0007",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "d0839eb052484b8f8e8a63f1190ce2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2469c01d97004b37b7c130a0a369338e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3870df2adba14c4d9d4e0fea39986507",
            "value": 1
          }
        },
        "227abe00592c4ca89c1b39fd80ad4622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f066178dd1541a3a57c8e17cd792b5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c65df30411a4520b2647687aacd0007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2469c01d97004b37b7c130a0a369338e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3870df2adba14c4d9d4e0fea39986507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}